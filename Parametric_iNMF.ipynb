{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0971f3a-f9d1-4ef6-8b40-b129709394fa",
   "metadata": {},
   "source": [
    "# Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f3d7a-bf93-4969-a44b-a936fbda0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive/Othercomputers/Il mio computer/Tesi/Computing/Datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ccb4a-38f8-4e57-a4bb-46d47ba2ce4d",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36eeeaad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.3 is available."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas~=1.3.5 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 1)) (1.3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn~=1.0.2 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 2)) (1.0.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You should consider upgrading via the 'C:\\Users\\mirco\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadr~=0.4.4 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 4)) (0.4.4)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 5)) (7.6.5)\n",
      "Requirement already satisfied: tqdm~=4.62.3 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 6)) (4.62.3)\n",
      "Requirement already satisfied: modin[dask] in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: rpy2 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 8)) (3.4.5)\n",
      "Requirement already satisfied: matplotlib~=3.5.1 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 9)) (3.5.1)\n",
      "Requirement already satisfied: nmf-torch in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 10)) (0.1.1)\n",
      "Requirement already satisfied: halo in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 11)) (0.0.31)\n",
      "Requirement already satisfied: numpy in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 12)) (1.22.2)\n",
      "Requirement already satisfied: scipy~=1.7.3 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 13)) (1.7.3)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 14)) (3.2.9)\n",
      "Requirement already satisfied: plotly in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 15)) (5.6.0)\n",
      "Requirement already satisfied: scikit-optimize in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 16)) (0.9.0)\n",
      "Collecting kaleido\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-win_amd64.whl (65.9 MB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas~=1.3.5->-r requirements.txt (line 1)) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas~=1.3.5->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn~=1.0.2->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn~=1.0.2->-r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (6.8.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (3.5.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (8.0.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (1.0.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (5.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm~=4.62.3->-r requirements.txt (line 6)) (0.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from modin[dask]->-r requirements.txt (line 7)) (21.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from modin[dask]->-r requirements.txt (line 7)) (2022.1.0)\n",
      "Requirement already satisfied: distributed>=2.22.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from modin[dask]->-r requirements.txt (line 7)) (2022.1.1)\n",
      "Requirement already satisfied: dask>=2.22.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from modin[dask]->-r requirements.txt (line 7)) (2022.1.1)\n",
      "Requirement already satisfied: cffi>=1.10.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rpy2->-r requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rpy2->-r requirements.txt (line 8)) (3.0.3)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rpy2->-r requirements.txt (line 8)) (4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib~=3.5.1->-r requirements.txt (line 9)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib~=3.5.1->-r requirements.txt (line 9)) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib~=3.5.1->-r requirements.txt (line 9)) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib~=3.5.1->-r requirements.txt (line 9)) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib~=3.5.1->-r requirements.txt (line 9)) (4.29.1)\n",
      "Requirement already satisfied: Cython in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nmf-torch->-r requirements.txt (line 10)) (0.29.27)\n",
      "Requirement already satisfied: torch in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nmf-torch->-r requirements.txt (line 10)) (1.10.2+cu113)\n",
      "Requirement already satisfied: log_symbols>=0.0.14 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from halo->-r requirements.txt (line 11)) (0.0.14)\n",
      "Requirement already satisfied: spinners>=0.0.24 in c:\\users\\mirco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from halo->-r requirements.txt (line 11)) (0.0.24)"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8d31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact, interact_manual\n",
    "from IPython.display import display\n",
    "from halo import HaloNotebook as Halo\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n",
    "from skopt import gp_minimize\n",
    "from random import randint\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from libraries.iNMF_wrapper import inmf\n",
    "from libraries.parameters_widgets import threaded\n",
    "import libraries.pca\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import contextlib\n",
    "import io\n",
    "import sys\n",
    "import math\n",
    "import pandas\n",
    "import sklearn.metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4c827-9803-4583-b858-2a0a506548c7",
   "metadata": {},
   "source": [
    "## Threaded execution\n",
    "Using modin and Dask slightly increases performances, but requires more RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ce8463-3247-43b5-bc46-db8d1838283c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c219e474a2434419a3506f1db57b5bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Threaded DataFrame manipulation')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(threaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f088d4-ccbd-4162-a884-8509c012faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if threaded.value:\n",
    "    import modin.pandas as pd\n",
    "    import dask\n",
    "    from dask.distributed import Client\n",
    "\n",
    "    # dask.config.set(temporary_directory='C:\\DaskTemp')\n",
    "    client = Client(n_workers=4, threads_per_worker=2)  # More workers = more RAM needed\n",
    "\n",
    "else:\n",
    "    import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bbf53f-8456-4599-8d4d-8bad4b501058",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fd2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_root = '../../Datasets/9_normalized'\n",
    "labels_path = '../../Datasets/6_downcasted'\n",
    "results_root = '../Results'\n",
    "output_root = '../../Datasets/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5bba9-e66d-45f5-b26b-c9da205ee394",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c786888b-bc0c-4730-8be6-75f7cd208846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(datasets_dict, threshold, ratio=None, n_components=None, log=False):\n",
    "    assert(ratio or n_components)\n",
    "\n",
    "    for name, dataset in (bar := tqdm(datasets_dict.items(), leave=False)):\n",
    "\n",
    "        if len(dataset.columns) > threshold:\n",
    "            bar.set_description(f'Computing PCA on {name}')\n",
    "            pca_results = compute_pca(dataset)\n",
    "            bar.set_description('Done')\n",
    "\n",
    "            if ratio is not None:\n",
    "                selected_components = cumulative_ratio(pca_results, ratio)\n",
    "            else:\n",
    "                selected_components = select_components(pca_results, n_components)\n",
    "\n",
    "            if log:\n",
    "                bar.write(f'{name}: selected {len(selected_components)}/{len(dataset.columns)} features ({len(selected_components)/len(dataset.columns)*100:.2f}%)')\n",
    "        else:\n",
    "            if log:\n",
    "                bar.write(f'{name}: smaller than features threshold')\n",
    "            selected_components = [(col, 0) for col in dataset.columns]\n",
    "\n",
    "        bar.set_description('Done')\n",
    "\n",
    "        datasets_dict[name] = dataset[[component[0] for component in selected_components]]\n",
    "\n",
    "    return datasets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c5616b-7d58-457f-ae46-320216951d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Given the dataset name and its extension, returns its name without the '.\\<extension>'\n",
    "def dataset_name(dataset_file: str, extension: str) -> str:\n",
    "    return dataset_file.replace(f'.{extension}', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37d5a373-c926-4e51-9067-67e655844e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataset and, optionally, the number of components; computes PCA and returns a list of pairs, where each pair is: <feature name>, <explained_variance_ratio>\n",
    "def compute_pca(dataset, n_components=None):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(dataset)\n",
    "    pca_results = [(pca.feature_names_in_[i], pca.explained_variance_ratio_[i]) for i in range(len(pca.components_))]\n",
    "\n",
    "    return pca_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bea9be34-dfdb-4093-b721-764e0eab990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_components(pca_results, n_components):\n",
    "    selected_components = pca_results[:n_components]\n",
    "\n",
    "    return selected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9778e0f-9bca-4b24-9fd9-380861a2d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects features to reach <ratio>\n",
    "def cumulative_ratio(pca_results, ratio):\n",
    "    selected_components = []\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while sum([component_ratio[1] for component_ratio in selected_components]) <= ratio:\n",
    "        selected_components.append(pca_results[i])\n",
    "        i += 1\n",
    "\n",
    "    return selected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "748dd420-2514-43b2-b354-8b5a3dbba187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True: CUDA libraries availables\n",
    "def gpu_available() -> bool:\n",
    "    return torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a24d5d-902c-461c-86a4-51999ab635fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads dataset from file. If bar is not None, updates its' description\n",
    "def load_dataset(dataset_file, root, bar: tqdm = None) -> pd.DataFrame:\n",
    "    name = dataset_name(dataset_file, 'xz')\n",
    "    path = os.path.join(root, dataset_file)\n",
    "    if bar:\n",
    "        bar.set_description(f'Loading \"{name}\" from \"{path}\"')\n",
    "    dataset = pd.read_pickle(path)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc77715-88b3-4128-b6f3-9827bc4ac1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters() -> dict:\n",
    "    parameters = {'tol': tol.value,\n",
    "                  'lam': lam.value,\n",
    "                  'batch_max_iter': batch_max_iter.value,\n",
    "                  'n_components': n_components.value}\n",
    "\n",
    "    if use_gpu.value:\n",
    "        parameters['use_gpu'] = use_gpu.value\n",
    "    else:\n",
    "        parameters['n_jobs'] = n_threads.value\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5c00f2a-57b6-46f0-9b54-f0278266da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call to iNMF helper\n",
    "def call_inmf(datasets_list: list, components, tol, lam, batch_max_iter) -> dict:\n",
    "    parameters = {'tol': tol,\n",
    "                  'lam': lam,\n",
    "                  'batch_max_iter': batch_max_iter,\n",
    "                  'n_components': components}\n",
    "\n",
    "    if use_gpu.value:\n",
    "        parameters['use_gpu'] = True\n",
    "    else:\n",
    "        parameters['n_jobs'] = n_threads.value\n",
    "\n",
    "    matrices = [dataset.transpose().to_numpy() for dataset in datasets_list]\n",
    "\n",
    "    with contextlib.redirect_stdout(None):\n",
    "        H, W, V, err = inmf(X=matrices, **parameters)\n",
    "\n",
    "    return {'H': H, 'W': W, 'V': V, 'err': err}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "669fb1c1-d59f-4691-9995-a2282bd49366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts decimals positions of the given value\n",
    "def count_decimals(number) -> int:\n",
    "    if isinstance(number, int):\n",
    "        return 0\n",
    "\n",
    "    string = str(number)\n",
    "\n",
    "    if '.' in string:\n",
    "        decimals = string.split('.')[1]\n",
    "        return len(decimals)\n",
    "    else:\n",
    "        return int(string.split('e-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09bde1fa-735c-4f47-a62d-49301c9b97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies Min-Max normalization to the passed pandas Series\n",
    "def min_max_norm(column: pd.Series):\n",
    "    col_min = min(column)\n",
    "    col_max = max(column)\n",
    "\n",
    "    col_range = col_max - col_min\n",
    "\n",
    "    if col_range == 0:\n",
    "        return column\n",
    "\n",
    "    return column.apply(lambda x: (x - col_min)/col_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40c37ff-b17d-4ab9-a407-ce4d0d7d854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies column-based Min-Max normalization to the passed pandas DataFrame\n",
    "def df_min_max_norm(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_ = df.copy()\n",
    "    for col_name in df_.columns:\n",
    "        df_[col_name] = df_[col_name].apply(min_max_norm)\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7d8bec9-f297-4300-923f-e6da088a60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list containing all possible sub-lists of l\n",
    "def sub_lists(l: list):\n",
    "    lists = []\n",
    "    for i in range(len(l) + 1):\n",
    "        for j in range(i):\n",
    "            if len(l[j: i]) > 1:\n",
    "                lists.append(l[j: i])\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3178f31-9355-4f03-a585-0c4ef3c0ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a pandas index containing all patients\n",
    "def get_patients(datasets: dict):\n",
    "    first_df = list(datasets.values())[0]\n",
    "    return first_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9019cc73-d560-4e0e-94a8-5d1bb1dbd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silhoutte(df, labels):\n",
    "    silhoutte = sklearn.metrics.silhouette_score(df, labels)\n",
    "\n",
    "    return silhoutte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef05f12b-38d5-4d00-a071-d6b8a9ca78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def W_to_df(W, patients):\n",
    "    df = pandas.DataFrame(W).transpose()\n",
    "    df.index = patients\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b162dfb6-2ba8-4dd0-9808-da3201a323d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pfi_dfi(df):\n",
    "    df = df.merge(labels, how='inner', left_index=True, right_index=True)\n",
    "    df['PFI'] = df['PFI'].astype(str)\n",
    "    df['DFI'] = df['DFI'].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df3aa034-6825-4ee2-bc60-b49a62f383f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_W(W, patients, labels, color_column):\n",
    "    fig = get_W_plot(W, patients, labels, color_column)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c257291d-6b67-4696-9807-806777ce3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_W_plot(W, patients, labels, color_column):\n",
    "    W_df = W_to_df(W, patients)\n",
    "\n",
    "    silhoutte = get_silhoutte(W_df, labels)\n",
    "\n",
    "    W_df = merge_pfi_dfi(W_df)\n",
    "\n",
    "    tridimensional = len(W_df.columns) - 2 == 3\n",
    "\n",
    "    axes = {'x': 0, 'y': 1}\n",
    "    fig_class = px.scatter\n",
    "\n",
    "    if tridimensional:\n",
    "        axes['z'] = 2\n",
    "        fig_class = px.scatter_3d\n",
    "\n",
    "    fig = fig_class(W_df, **axes, color=color_column, width=800, height=800,\n",
    "                    title=f'{3 if tridimensional else 2} Components | Silhoutte: {silhoutte}')\n",
    "    fig.update_traces(marker=dict(size=3))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f757cba-ecbd-41af-b8a5-0aa90dfcdb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_vs_silhoutte(results, parameter_name, title):\n",
    "    parameter_header = f'{parameter_name.capitalize()}'\n",
    "    df = pandas.DataFrame(results, columns=[parameter_header, 'Error',  'Silhoulette'])\n",
    "    fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Error\", \"Silhoulette\"))\n",
    "    fig.append_trace(go.Scatter(x=df[parameter_header], y=df['Error']), row=1, col=1)\n",
    "    fig.append_trace(go.Scatter(x=df[parameter_header], y=df['Silhoulette']), row=2, col=1)\n",
    "    fig.update_layout(height=800, showlegend=False, title_text=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1d356d0-53ea-42f9-8908-03ac78327e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_datasets(datasets_root) -> dict:\n",
    "    datasets_filenames = os.listdir(datasets_root)\n",
    "    if 'tcga_cdr_brca_labels.xz' in datasets_filenames:\n",
    "        datasets_filenames.remove('tcga_cdr_brca_labels.xz')\n",
    "\n",
    "    datasets = {}\n",
    "\n",
    "    for dataset in (bar := tqdm(datasets_filenames)):\n",
    "        datasets[dataset_name(dataset, 'xz')] = load_dataset(dataset, datasets_root, bar)\n",
    "\n",
    "        bar.set_description('Datasets loaded')\n",
    "\n",
    "    print(f'{len(datasets)} datasets loaded:', '\\n'.join(datasets.keys()), sep='\\n')\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4d2bf-ea6d-46e4-8cfb-95f5ea7c865d",
   "metadata": {},
   "source": [
    "### Labels loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63a7814a-0d1e-41fa-9b84-a075ad64e120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536b6e93ab9c4ce694880c88462d4cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "with Halo(text=f'Loading labels dataset...', spinner='dots'):\n",
    "    labels = load_dataset('tcga_cdr_brca_labels.xz', labels_path)\n",
    "\n",
    "if not isinstance(labels, pandas.DataFrame):\n",
    "    labels = labels._to_pandas()\n",
    "\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f661c-9624-46a7-85c8-e43960ac096e",
   "metadata": {},
   "source": [
    "## Fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86397f68-e66c-4fa4-9c7e-a331c91d11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence tolerance\n",
    "tol = 1e-4\n",
    "\n",
    "# Regularization parameter\n",
    "lam = 1\n",
    "\n",
    "batch_max_iter = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e054814-b9bd-4774-bbbf-06891e19dec4",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9db6264e-d55e-4199-9047-b6f435ef0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_names = [dataset_name(filename, 'xz') for filename in os.listdir(datasets_root)]\n",
    "\n",
    "datasets_lists = sub_lists(list(datasets_names))\n",
    "n_components = [2, 3, 100, 200]\n",
    "pca_param = [0.75, 0.9, 100, 200]  # <=1: cumulative ratio, >1: max selected components\n",
    "\n",
    "parameters = {'datasets': datasets_lists,\n",
    "              'n_components': n_components,\n",
    "              'pca': pca_param}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf31099-42f5-441c-9880-99623a6e5850",
   "metadata": {},
   "source": [
    "## Generate tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5492bc91-769e-4e4f-ae15-80c72d2a7089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bf63bcda96417db69593cfd11d6059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=0, description='Completed tests:', max=9999999999999)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "completed_tests = widgets.BoundedIntText(value=0, min=0, max=9999999999999, description='Completed tests:')\n",
    "display(completed_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ec7d8c2-96fc-4916-b935-74ed3ed53636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tests\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations of parameters\n",
    "prod = list(product(*list(parameters.values())))\n",
    "\n",
    "# Build a category: values dictionary for each test\n",
    "tests = [{key: p[i] for i, key in enumerate(parameters.keys())} for p in prod]\n",
    "\n",
    "# Remove already completed tests\n",
    "tests = tests[completed_tests.value:]\n",
    "\n",
    "tests = [test for test in tests if test['n_components'] != 200]\n",
    "\n",
    "tests = [{'datasets': ['miRNA_mor', 'miRNA_vst', 'mRNA_mor', 'mRNA_vst'],\n",
    "          'n_components': 100,\n",
    "          'pca': 100}]\n",
    "\n",
    "print(f'{len(tests)} tests')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882022df-50b7-4231-96c2-25d2013335b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hardware parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f7c0740-81eb-48f4-b62d-dfe204f1a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int64_info = np.iinfo(np.int64)\n",
    "max_int = int64_info.max\n",
    "\n",
    "# Threads number\n",
    "n_threads = widgets.IntSlider(value=-1, min=-1, max=64, step=1, description='CPU threads:', continuous_update=False)\n",
    "\n",
    "# Use GPU\n",
    "use_gpu = widgets.Checkbox(value=False, description='Use GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "705faa88-a50a-4ba7-9ec2-1b20ec5cecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays hardware related parameters\n",
    "def display_hw_parameters():\n",
    "    if gpu_available():\n",
    "        display(use_gpu)\n",
    "        display(n_threads)\n",
    "    else:\n",
    "        display(n_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d48b893-4547-48a1-bb74-be03032975cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9144f59756004532b64560ddc8df5062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Use GPU')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bbd9389949438e90b058715c2c5bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=-1, continuous_update=False, description='CPU threads:', max=64, min=-1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_hw_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6716ac-427d-4c2a-9d17-6f13a480f910",
   "metadata": {},
   "source": [
    "## Datasets loading and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4986d8c0-2626-4cc8-acf7-13543d461121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64bf7a5a0e943c4a6cd3050ef5908de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 datasets loaded:\n",
      "clinical_data\n",
      "cnv.score\n",
      "met_Mval\n",
      "miRNA_mor\n",
      "miRNA_vst\n",
      "mRNA_mor\n",
      "mRNA_vst\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d251141d65a4452ca199561e8941becc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_all_datasets(datasets_root)\n",
    "\n",
    "for name, dataset in (bar := tqdm(datasets.items())):\n",
    "    bar.set_description(f'Normalizing {name}...')\n",
    "    #datasets[name] = dataset.apply(min_max_norm)\n",
    "    bar.set_description('Normalization done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4706e-e1eb-4304-805e-508bd9796c7e",
   "metadata": {},
   "source": [
    "# Parametric iNMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32156e87-1fda-4f23-a081-431d42054585",
   "metadata": {},
   "source": [
    "### PCA phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4f82256-ac45-4cbe-b136-655e0fc3c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_buffer_key(test):\n",
    "    return f\"{test['pca']}-{test['datasets']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ea38d39-0c21-4087-8fc8-81428dbee639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_phase(pca_buffer: dict, test):\n",
    "    pca_param = test['pca']\n",
    "    if pca_buffer_key(test) not in pca_buffer:\n",
    "        if pca_param <= 1:\n",
    "            pca_buffer[pca_buffer_key(test)] = pca(datasets.copy(), threshold=100, ratio=pca_param)\n",
    "\n",
    "        else:\n",
    "            pca_buffer[pca_buffer_key(test)] = pca(datasets.copy(), threshold=100, n_components=pca_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1258a3-73dc-4114-85db-e18f3e893f55",
   "metadata": {},
   "source": [
    "### Report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a292388a-76df-4658-a176-0949d4b89c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(test, err, silhoutte):\n",
    "    report = test\n",
    "    report['error'] = err\n",
    "    report['silhoutte'] = silhoutte\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bccfa2-8240-4c2d-8ffe-e31d791c3160",
   "metadata": {},
   "source": [
    "### Image to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38c0d124-f615-4928-958b-ea013ab7726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_dir(now):\n",
    "    dir_name = now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "\n",
    "    path = os.path.join(results_root, dir_name)\n",
    "    if os.path.isdir(path):\n",
    "        alt = 0\n",
    "        while os.path.isdir(os.path.join(results_root, f'{dir_name}_{alt}')):\n",
    "            alt += 1\n",
    "\n",
    "        path = os.path.join(results_root, f'{dir_name}_{alt}')\n",
    "\n",
    "    os.mkdir(path)\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a908b876-51b5-4312-8036-628a67d6afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_description(result):\n",
    "    description = '\\n'.join([f'{cat.capitalize()}: {values}' for cat, values in result.items()])\n",
    "\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a8abffb-b02b-4bbc-b023-c2124c6bcb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig, result):\n",
    "    description = generate_description(result)\n",
    "\n",
    "    now = datetime.now()\n",
    "    result_dir = create_result_dir(now)\n",
    "    fig_name = f'{now.strftime(\"%d-%m-%Y_%H-%M-%S\")}.png'\n",
    "    desc_name = f'{now.strftime(\"%d-%m-%Y_%H-%M-%S\")}.txt'\n",
    "\n",
    "    fig_path = os.path.join(results_root, result_dir, fig_name)\n",
    "    desc_path = os.path.join(results_root, result_dir, desc_name)\n",
    "\n",
    "    with open(desc_path, 'w') as file:\n",
    "        file.write(description)\n",
    "\n",
    "    fig.write_image(fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f263f68d-abf9-4c11-9f3d-a13f758ac83e",
   "metadata": {},
   "source": [
    "### Results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e7a8b0e-d16e-4ebb-a7af-b208f1288d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, name):\n",
    "    path = os.path.join(results_root, name)\n",
    "    results.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f27c077f-47c0-40a4-a5ff-16358fe38e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c019f87309493d9cc7006ba04f7b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256a39184a094b849dd57d10918e3f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m tests_bar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m tests_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA phase\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mpca_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpca_datasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m tests_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA completed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m tests_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing iNMF\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36mpca_phase\u001b[1;34m(pca_buffer, test)\u001b[0m\n\u001b[0;32m      5\u001b[0m     pca_buffer[pca_buffer_key(test)] \u001b[38;5;241m=\u001b[39m pca(datasets\u001b[38;5;241m.\u001b[39mcopy(), threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, ratio\u001b[38;5;241m=\u001b[39mpca_param)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     pca_buffer[pca_buffer_key(test)] \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpca_param\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mpca\u001b[1;34m(datasets_dict, threshold, ratio, n_components, log)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m>\u001b[39m threshold:\n\u001b[0;32m      7\u001b[0m     bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing PCA on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     pca_results \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_pca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ratio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mcompute_pca\u001b[1;34m(dataset, n_components)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_pca\u001b[39m(dataset, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m     pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39mn_components)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     pca_results \u001b[38;5;241m=\u001b[39m [(pca\u001b[38;5;241m.\u001b[39mfeature_names_in_[i], pca\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pca\u001b[38;5;241m.\u001b[39mcomponents_))]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pca_results\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:382\u001b[0m, in \u001b[0;36mPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:457\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:492\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    490\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n\u001b[1;32m--> 492\u001b[0m U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# flip eigenvectors' sign to enforce deterministic output\u001b[39;00m\n\u001b[0;32m    494\u001b[0m U, Vt \u001b[38;5;241m=\u001b[39m svd_flip(U, Vt)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py:127\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[0;32m    123\u001b[0m lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    124\u001b[0m                        compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# perform decomposition\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m u, s, v, info \u001b[38;5;241m=\u001b[39m gesXd(a1, compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, lwork\u001b[38;5;241m=\u001b[39mlwork,\n\u001b[0;32m    128\u001b[0m                       full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices, overwrite_a\u001b[38;5;241m=\u001b[39moverwrite_a)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_columns = list(parameters.keys()) + ['error', 'silhoutte']\n",
    "results = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "now = datetime.now()\n",
    "csv_name = f'{now.strftime(\"%d-%m-%Y_%H-%M-%S\")}.csv'\n",
    "\n",
    "pca_datasets = {}\n",
    "\n",
    "for test in (tests_bar := tqdm(tests)):\n",
    "    tests_bar.set_postfix_str(f'{test}')\n",
    "\n",
    "    tests_bar.set_description('PCA phase')\n",
    "    pca_phase(pca_datasets, test)\n",
    "    tests_bar.set_description('PCA completed')\n",
    "\n",
    "    tests_bar.set_description('Computing iNMF')\n",
    "    pca_datasets_subset = {name: dataset for name, dataset in pca_datasets[pca_buffer_key(test)].items() if name in test['datasets']}\n",
    "\n",
    "    _, W, _, err = inmf(datasets=pca_datasets_subset.values(), n_components=test['n_components'], tol=tol, lam=lam, batch_max_iter=batch_max_iter)\n",
    "    silhoutte = get_silhoutte(W_to_df(W, get_patients(pca_datasets[pca_buffer_key(test)])), labels['PFI'])\n",
    "\n",
    "    report = generate_report(test, err, silhoutte)\n",
    "    results = results.append(report, ignore_index=True)\n",
    "\n",
    "    if 2 <= test['n_components'] <= 3:\n",
    "        tests_bar.set_description('Saving image')\n",
    "        fig = get_W_plot(W, get_patients(datasets), labels['PFI'], color_column='PFI')\n",
    "        save_fig(fig, report)\n",
    "\n",
    "    tests_bar.set_description('Saving results')\n",
    "    save_results(results, csv_name)\n",
    "\n",
    "    tests_bar.set_description('Cooling down CPU')\n",
    "    # sleep(5)  # Useful when computing iNMF on CPU\n",
    "\n",
    "    tests_bar.set_description('Done')\n",
    "    tests_bar.set_postfix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c736c31a-a96c-4b57-9dce-c59e171f3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tests[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "900125f3-dac8-42d1-9f23-4067976f565b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca_datasets_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _, W, _, err \u001b[38;5;241m=\u001b[39m inmf(datasets\u001b[38;5;241m=\u001b[39m\u001b[43mpca_datasets_subset\u001b[49m, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, tol\u001b[38;5;241m=\u001b[39mtol, lam\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(lam), batch_max_iter\u001b[38;5;241m=\u001b[39mbatch_max_iter, n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, use_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, algo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhalsvar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pca_datasets_subset' is not defined"
     ]
    }
   ],
   "source": [
    "_, W, _, err = inmf(datasets=pca_datasets_subset, n_components=3, tol=tol, lam=float(lam), batch_max_iter=batch_max_iter, n_threads=-1, use_gpu=True, algo='halsvar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
